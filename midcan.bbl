\begin{thebibliography}{}

\bibitem[Bandara et~al., 2019]{Bandara2019-bg}
Bandara, K., Shi, P., Bergmeir, C., Hewamalage, H., Tran, Q., and Seaman, B.
  (2019).
\newblock Sales demand forecast in e-commerce using a long {Short-Term} memory
  neural network methodology.
\newblock In {\em Neural Information Processing}, pages 462--474. Springer
  International Publishing.

\bibitem[Barrow and Crone, 2016]{Barrow2016-yv}
Barrow, D.~K. and Crone, S.~F. (2016).
\newblock A comparison of {AdaBoost} algorithms for time series forecast
  combination.
\newblock {\em Int. J. Forecast.}, 32(4):1103--1119.

\bibitem[Ben~Taieb et~al., 2011]{Ben_Taieb2011-iu}
Ben~Taieb, S., Bontempi, G., Atiya, A., and Sorjamaa, A. (2011).
\newblock A review and comparison of strategies for multi-step ahead time
  series forecasting based on the {NN5} forecasting competition.

\bibitem[Borovykh et~al., 2017]{Borovykh2017-le}
Borovykh, A., Bohte, S., and Oosterlee, C.~W. (2017).
\newblock Conditional time series forecasting with convolutional neural
  networks.

\bibitem[Crone, 2008]{Crone2008-ye}
Crone, S.~F. (2008).
\newblock {NN5} competition.
\newblock \url{http://www.neural-forecasting-competition.com/NN5/}.
\newblock Accessed: 2017-8-18.

\bibitem[Crone et~al., 2011]{Crone2011-vv}
Crone, S.~F., Hibon, M., and Nikolopoulos, K. (2011).
\newblock Advances in forecasting with neural networks? empirical evidence from
  the {NN3} competition on time series prediction.
\newblock {\em Int. J. Forecast.}, 27(3):635--660.

\bibitem[Fei and Yeung, 2015]{Fei2015-vh}
Fei, M. and Yeung, D.~Y. (2015).
\newblock Temporal models for predicting student dropout in massive open online
  courses.
\newblock In {\em 2015 {IEEE} International Conference on Data Mining Workshop
  ({ICDMW})}, pages 256--263.

\bibitem[Godahewa et~al., 2020]{Godahewa2020-wg}
Godahewa, R., Bergmeir, C., Webb, G.~I., and Montero-Manso, P. (2020).
\newblock A strong baseline for weekly time series forecasting.
\newblock {\em ArXiv}.

\bibitem[He et~al., 2016]{He2016-wm}
He, K., Zhang, X., Ren, S., and Sun, J. (2016).
\newblock Deep residual learning for image recognition.
\newblock In {\em 2016 {IEEE} Conference on Computer Vision and Pattern
  Recognition ({CVPR})}, pages 770--778.

\bibitem[Hewamalage et~al., 2021]{Hewamalage2021-hg}
Hewamalage, H., Bergmeir, C., and Bandara, K. (2021).
\newblock Recurrent neural networks for time series forecasting: Current status
  and future directions.
\newblock {\em Int. J. Forecast.}, 37(1):388--427.

\bibitem[Hyndman, 2016]{Hyndman2016-ej}
Hyndman, R.~J. (2016).
\newblock {Q\&A} time | rob {J} hyndman.
\newblock \url{https://robjhyndman.com/hyndsight/qa-time/}.
\newblock Accessed: 2017-9-5.

\bibitem[Hyndman and Billah, 2003]{Hyndman2003-kc}
Hyndman, R.~J. and Billah, B. (2003).
\newblock Unmasking the theta method.
\newblock {\em Int. J. Forecast.}, 19(2):287--290.

\bibitem[Ilies et~al., 2007]{Ilies2007-ej}
Ilies, I., Jaeger, H., Kosuchinas, O., Rincon, M., and {others} (2007).
\newblock Stepping forward through echoes of the past: forecasting with echo
  state networks.
\newblock {\em URL: http://www. neural-forecastingcompetition.
  com/downloads/methods/27-NN3 Herbert Jaeger report. pdf}.

\bibitem[Januschowski et~al., 2020]{Januschowski2020-ud}
Januschowski, T., Gasthaus, J., Wang, Y., Salinas, D., Flunkert, V.,
  Bohlke-Schneider, M., and Callot, L. (2020).
\newblock Criteria for classifying forecasting methods.
\newblock {\em Int. J. Forecast.}, 36(1):167--177.

\bibitem[Kang et~al., 2019]{Kang2019-dy}
Kang, Y., Hyndman, R.~J., and Li, F. (2019).
\newblock {GRATIS}: {GeneRAting} {TIme} series with diverse and controllable
  characteristics.

\bibitem[Li et~al., 2019]{Li2019-io}
Li, S., Jin, X., Xuan, Y., Zhou, X., Chen, W., Wang, Y.-X., and Yan, X. (2019).
\newblock Enhancing the locality and breaking the memory bottleneck of
  transformer on time series forecasting.
\newblock In Wallach, H., Larochelle, H., and Beygelzimer, A., editors, {\em
  Advances in Neural Information Processing Systems}, volume~32. Curran
  Associates, Inc.

\bibitem[Lim et~al., 2021]{Lim2021-il}
Lim, B., Ar{\i}k, S.~{\"O}., Loeff, N., and Pfister, T. (2021).
\newblock Temporal fusion transformers for interpretable multi-horizon time
  series forecasting.
\newblock {\em Int. J. Forecast.}

\bibitem[Makridakis and Hibon, 2000]{Makridakis2000-ih}
Makridakis, S. and Hibon, M. (2000).
\newblock The {M3-Competition}: results, conclusions and implications.
\newblock {\em Int. J. Forecast.}, 16(4):451--476.

\bibitem[Makridakis and Spiliotis, 2021]{Makridakis2021-ro}
Makridakis, S. and Spiliotis, E. (2021).
\newblock The {M5} competition and the future of human expertise in
  forecasting.
\newblock {\em Foresight: The International Journal of Applied Forecasting},
  (60):33--37.

\bibitem[Montero-Manso and Hyndman, 2021]{Montero-Manso2021-es}
Montero-Manso, P. and Hyndman, R.~J. (2021).
\newblock Principles and algorithms for forecasting groups of time series:
  Locality and globality.
\newblock {\em Int. J. Forecast.}

\bibitem[Nelson et~al., 1999]{Nelson1999-bd}
Nelson, M., Hill, T., Remus, W., and O'Connor, M. (1999).
\newblock Time series forecasting using neural networks: should the data be
  deseasonalized first?
\newblock {\em J. Forecast.}, 18(5):359--367.

\bibitem[Oreshkin et~al., 2019]{Oreshkin2019-tq}
Oreshkin, B.~N., Carpov, D., Chapados, N., and Bengio, Y. (2019).
\newblock {N-BEATS}: Neural basis expansion analysis for interpretable time
  series forecasting.

\bibitem[Rahman et~al., 2016]{Rahman2016-os}
Rahman, M.~M., Islam, M.~M., Murase, K., and Yao, X. (2016).
\newblock Layered ensemble architecture for time series forecasting.
\newblock {\em IEEE Trans Cybern}, 46(1):270--283.

\bibitem[Rangapuram et~al., 2018]{Rangapuram2018-zq}
Rangapuram, S.~S., Seeger, M.~W., Gasthaus, J., Stella, L., Wang, Y., and
  Januschowski, T. (2018).
\newblock Deep state space models for time series forecasting.
\newblock In Bengio, S., Wallach, H., Larochelle, H., Grauman, K.,
  Cesa-Bianchi, N., and Garnett, R., editors, {\em Advances in Neural
  Information Processing Systems}, volume~31. Curran Associates, Inc.

\bibitem[Salinas et~al., 2020]{Salinas2020-dz}
Salinas, D., Flunkert, V., Gasthaus, J., and Januschowski, T. (2020).
\newblock {DeepAR}: Probabilistic forecasting with autoregressive recurrent
  networks.
\newblock {\em Int. J. Forecast.}, 36(3):1181--1191.

\bibitem[Sen et~al., 2019]{Sen2019-jj}
Sen, R., Yu, H.-F., and Dhillon, I.~S. (2019).
\newblock Think globally, act locally: A deep neural network approach to
  {High-Dimensional} time series forecasting.
\newblock In Wallach, H., Larochelle, H., and Beygelzimer, editors, {\em
  Advances in Neural Information Processing Systems}, volume~32. Curran
  Associates, Inc.

\bibitem[Smyl, 2016]{Smyl2016-ee}
Smyl, S. (2016).
\newblock Forecasting short time series with {LSTM} neural networks.
\newblock \url{https://gallery.cortanaintelligence.com/Tutorial/
  Forecasting-Short-Time-Series-with-LSTM-Neural-Networks-2}.
\newblock Accessed: 2017-8-28.

\bibitem[Smyl, 2019]{Smyl2019-cb}
Smyl, S. (2019).
\newblock A hybrid method of exponential smoothing and recurrent neural
  networks for time series forecasting.
\newblock {\em Int. J. Forecast.}

\bibitem[Suilin, 2018]{Suilin2018-tc}
Suilin, A. (2018).
\newblock kaggle-web-traffic.
\newblock \url{https://github.com/Arturus/kaggle-web-traffic}.
\newblock Accessed: 2020-2-10.

\bibitem[Yan, 2012]{Yan2012-dh}
Yan, W. (2012).
\newblock Toward automatic time-series forecasting using neural networks.
\newblock {\em IEEE Trans Neural Netw Learn Syst}, 23(7):1028--1039.

\bibitem[Zhang et~al., 1998]{Zhang1998-tq}
Zhang, G., Patuwo, B.~E., and Hu, M.~Y. (1998).
\newblock Forecasting with artificial neural networks:: The state of the art.
\newblock {\em Int. J. Forecast.}, 14(1):35--62.

\bibitem[Zhang and Qi, 2005]{Zhang2005-pk}
Zhang, G.~P. and Qi, M. (2005).
\newblock Neural network forecasting for seasonal and trend time series.
\newblock {\em Eur. J. Oper. Res.}, 160(2):501--514.

\bibitem[Zimmermann et~al., 2012]{Zimmermann2012-cp}
Zimmermann, H.-G., Tietz, C., and Grothmann, R. (2012).
\newblock Forecasting with recurrent neural networks: 12 tricks.
\newblock In {\em Neural Networks: Tricks of the Trade}, Lecture Notes in
  Computer Science, pages 687--707. Springer, Berlin, Heidelberg.

\end{thebibliography}
